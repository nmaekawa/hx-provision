---
#
# playbook assumes being applied to ec2 instance since cloudwatch-related
#

- hosts: '{{ target_hosts | default("tag_service_postgres", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      project_name: '{{ hostvars[inventory_hostname].ec2_tag_project | mandatory}}'
      service_name: '{{ hostvars[inventory_hostname].ec2_tag_service | mandatory}}'
      cluster_env: '{{ (hostvars[inventory_hostname].ec2_tag_cluster == "prod")| ternary("prod", "devo") }}'
      cloudwatch_namespace: '{{ cloudwatch_namespace_prefix }}/{{ project_name }}'
  vars_files:
      - vars/common_vars.yml
      - vars/postgres_vars.yml

  tasks:

      - debug:
          msg: "project_name={{ project_name }}; service_name={{ service_name }}; cluster_env={{ cluster_env }}; namespace={{ cloudwatch_namespace }}"

      # install aws scripts
      - include_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_scripts.yml
        vars:
          script_install_dir: "{{ default_cronjob_scripts_dir }}"

      - name: s3 backup | cronjob for postgres log->s3
        cron:
          name: "s3 sync for postgres log"
          user: postgres
          special_time: daily  # check when the logs are being rotated to schedule after that
          state: present
          job: >
            /user/bin/aws s3 sync
            {{ db_log_dir }}
            s3://{{ s3_backup_bucket_name }}/{{ cluster_env }}/{{ project_name }}/{{ service_name }}_{{ ansible_ec2_instance_id }}

      - name: install s3 cronjob for postgres databases
        cron:
          name: "s3 sync for postgres databases"
          user: postgres
          special_time: daily  # check when dumps are performed to schedule after that
          state: present
          job: >
            /user/bin/aws s3 sync
            {{ db_backup_dir }}
            s3://{{ s3_backup_bucket_name }}/{{ cluster_env }}/{{ project_name }}/{{ service_name }}_{{ ansible_ec2_instance_id }}



