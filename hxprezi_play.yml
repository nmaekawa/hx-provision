---
#
# assumes common_play.yml already applied to all involved inventory
#

- hosts: '{{ target_hosts | default("tag_service_hxprezi", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      local_user:
          name: '{{ service_name }}'
          authorized: []
  vars_files:
      - vars/common_vars.yml
      - vars/hxprezi_vars.yml

  tasks:
      - include_role:
          name: external/nmaekawa.apt
        vars:
          apt_other_packages: "{{ apt_required_packages_hxprezi }}"

      - include_role:
          name: external/Stouts.users
        vars:
          users_users: '{{ [local_user] }}'


- hosts: '{{ target_hosts | default("tag_service_hxprezi", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  vars:
      local_manifests_path_tar_gz: /Volumes/Projects/Dev_Team/images/local_manifests_hxprezi_v3_0_0.tar.gz
  vars_files:
      - vars/common_vars.yml
      - vars/hxprezi_vars.yml
  handlers:
    - include_tasks: handlers/main.yml

  tasks:
      - name: install webapp
        include_role:
            name: webapp_install

      - name: config nginx
        include_role:
            name: nginx
        vars:
            nginx_template_path: roles/nginx/templates/nginx_hxprezi.j2


      - name: transfer local manifests
        copy:
            src: '{{ local_manifests_path_tar_gz }}'
            dest: '{{ service_data_dir }}'
            owner: '{{ service_user }}'
            group: '{{ service_group }}'
        when: ec2_tag_cluster == 'vagrant' and ( local_manifests_path_tar_gz is defined )

      - name: unarchive local manifests tar.gz
        unarchive:
            src: '{{ service_data_dir }}/{{ local_manifests_path_tar_gz | basename }}'
            dest: '{{ service_data_dir }}'
            owner: '{{ service_user }}'
            group: '{{ service_group }}'
            remote_src: yes
        when: ec2_tag_cluster == 'vagrant' and ( local_manifests_path_tar_gz is defined )


- hosts: '{{ target_hosts | default("tag_service_hxprezi", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      project_name: '{{ hostvars[inventory_hostname].ec2_tag_project | mandatory}}'
      cluster_env: '{{ (hostvars[inventory_hostname].ec2_tag_cluster == "prod")| ternary("prod", "devo") }}'
      cronjob_scripts_dir: '/usr/local/bin'
      cloudwatch_namespace: '{{ cloudwatch_namespace_prefix }}/{{ project_name }}'
  vars_files:
      - vars/common_vars.yml
      - vars/hxprezi_vars.yml

  tasks:

      - debug:
          msg: "project_name={{ project_name }}; service_name={{ service_name }}; cluster_env={{ cluster_env }}; namespace={{ cloudwatch_namespace }}"

      #
      # 19nov18 naomi: skipping since this is done via cloudformation
      # -------------------------------------------------------------
      # associate proper instance profile for permissions
      #- import_tasks: roles/external/nmaekawa.iam-instance-profile/tasks/associate_iam_instance_profile.yml
      #  vars:
      #      instance_profile_name: "hx_{{ project_name }}-{{ cluster_env }}_instance_profile"
      #      instance_id_to_associate: '{{ hostvars[inventory_hostname].ec2_id }}'
      #  when: "use_aws"

      - import_role:
          name: external/Stouts.users
        vars:
            users_enabled: yes
            users_users:
                - name: cloudwatch
                  authorized: []
            users_to_install:
                - cloudwatch
        when: "use_aws"

      - import_role:
          name: external/nmaekawa.cloudwatch
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: cloudwatch
        when: "use_aws"

      # install script for syslog backup
      - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_backup.yml
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: root
            s3_backup_prefix: '{{ cluster_env }}/{{ project_name }}'
            file_backup_prefix: '{{ service_name }}_{{ ansible_ec2_instance_id }}'
            files_to_backup:
                - /var/log/syslog.1
        when: "use_aws"

      # install script for nginx logs backup
      - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_backup.yml
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: root
            s3_backup_prefix: '{{ cluster_env }}/{{ project_name }}'
            file_backup_prefix: '{{ service_name }}_{{ ansible_ec2_instance_id }}'
            files_to_backup:
                - /var/log/nginx/access.log.1
                - /var/log/nginx/error.log.1
        when: "use_aws"


      # install script for manifests sync, if manifests instance
      - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_sync.yml
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: "{{ service_name }}"
            s3_sync_bucket_name: '{{ s3_source_bucket_name }}'
            s3_sync_prefix: 'manifests'
            target_s3_sync_dir: '/opt/hxprezi/data'
        when: "use_aws"

      - name: run initial s3 sync for manifests
        shell: >
            /usr/bin/aws s3 sync
            "s3://{{ s3_source_bucket_name }}/manifests"
            "/opt/hxprezi/data"
            2>&1 | logger -t "[s3 sync INITIAL]"
        when: "use_aws"


