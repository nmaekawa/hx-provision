---
#
# assumes common_play.yml already applied to all involved inventory
#

- hosts: '{{ target_hosts | default("tag_service_hxprezi", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      local_user:
          name: '{{ service_name }}'
          authorized: []
  vars_files:
      - vars/common_vars.yml
      - vars/hxprezi_vars.yml

  tasks:
      - include_role:
          name: external/nmaekawa.apt
        vars:
          apt_other_packages: "{{ apt_required_packages_hxprezi }}"

      - include_role:
          name: external/Stouts.users
        vars:
          users_users: '{{ [local_user] }}'


- hosts: '{{ target_hosts | default("tag_service_hxprezi", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  vars:
      local_manifests_path_tar_gz: /Volumes/Projects/Dev_Team/images/local_manifests_hxprezi_v3_0_0.tar.gz
  vars_files:
      - vars/common_vars.yml
      - vars/hxprezi_vars.yml
  handlers:
    - include_tasks: handlers/main.yml

  tasks:
      - name: install webapp
        include_role:
            name: webapp_install

      - name: config nginx
        include_role:
            name: nginx
        vars:
            nginx_template_path: roles/nginx/templates/nginx_hxprezi.j2

      - name: transfer local manifests
        copy:
            src: '{{ local_manifests_path_tar_gz }}'
            dest: '{{ service_data_dir }}'
            owner: '{{ service_user }}'
            group: '{{ service_group }}'
        when: ec2_tag_cluster == 'vagrant' and ( local_manifests_path_tar_gz is defined )

      - name: unarchive local manifests tar.gz
        unarchive:
            src: '{{ service_data_dir }}/{{ local_manifests_path_tar_gz | basename }}'
            dest: '{{ service_data_dir }}'
            owner: '{{ service_user }}'
            group: '{{ service_group }}'
            remote_src: yes
        when: ec2_tag_cluster == 'vagrant' and ( local_manifests_path_tar_gz is defined )


  # install log/metrics scripts, syslog to s3, put-metrics to cloudwatch
- import_playbook: cloudwatch_scripts_play.yml


- import_playbook: nginx_backup_play.yml


- import_playbook: route53_play.yml



- hosts: '{{ target_hosts | default("tag_service_hxprezi", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
    project_name: '{{ hostvars[inventory_hostname].ec2_tag_project | mandatory}}'
    service_role: '{{ hostvars[inventory_hostname].ec2_tag_service | mandatory}}'
    cluster_env: '{{ (hostvars[inventory_hostname].ec2_tag_cluster == "prod")| ternary("prod", "devo") }}'
    cloudwatch_namespace: '{{ cloudwatch_namespace_prefix }}/{{ project_name }}'
  vars_files:
    - vars/common_vars.yml
    - vars/hxprezi_vars.yml
    - roles/external/nmaekawa.cloudwatch/defaults/main.yml

  tasks:
    # install script for manifests sync, if manifests instance
    - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_sync_cronjob.yml
      vars:
        cronjob_owner: "{{ service_name }}"
        s3_sync_bucket_name: '{{ s3_source_bucket_name }}'
        s3_sync_prefix: 'manifests'
        target_s3_sync_dir: '/opt/hxprezi/data'
      when: ec2_tag_cluster == 'prod'

    - name: run initial s3 sync for manifests
      become_user: "{{ service_name }}"
      shell: >
        /usr/bin/aws s3 sync
        "s3://{{ s3_source_bucket_name }}/manifests"
        "/opt/hxprezi/data"
        2>&1 | logger -t "[s3 sync INITIAL]"
      when: ec2_tag_cluster == 'prod'


  #
  # TODO: at some point have to detangle service_role and service_name...
  #

