---
#
# assumes common_play.yml already applied to all involved inventory
#

- hosts: '{{ target_hosts | default("all", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      local_user:
          name: '{{ service_user }}'
          authorized: []
  vars_files:
      - vars/common_vars.yml
      - vars/loris_dedicated_varnish_vars.yml

  tasks:
      - include_role:
          name: external/nmaekawa.apt
        vars:
          apt_other_packages: "{{ apt_required_packages_loris }}"

      - include_role:
          name: external/Stouts.users
        vars:
          users_users: '{{ [local_user] }}'



- hosts: '{{ target_hosts | default("tag_service_loris", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars_files:
      - vars/common_vars.yml
      - vars/loris_dedicated_varnish_vars.yml

  handlers:
    - include: handlers/main.yml

  tasks:
      - include_role:
          name: external/nmaekawa.apt
        vars:
            apt_other_packages: '{{ apt_required_packages_loris }}'

      - name: setup loris
        include_role:
            name: hx.loris
        vars:
            local_image_sample_path_tar_gz: '/Volumes/Projects/Dev_Team/images/images_prod_20180824.tar.gz'


- hosts: '{{ target_hosts | default("all", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      is_varnish: '{{ hostvars[inventory_hostname].ec2_tag_service | regex_search("varnish") }}'
      varnish_default_vcl_template_path: 'roles/varnishlog/templates/default_dedicated.vcl.j2'
      varnish_be: "{% if hostvars[inventory_hostname].ec2_tag_service == 'idsvarnish' %}\
                        {{ varnish_instances.ids.backend }}\
                   {% elif hostvars[inventory_hostname].ec2_tag_service == 'hxvarnish' %}\
                            {{ varnish_instances.hx.backend }}\
                   {% endif %}"
      varnish_listen_port: "{% if hostvars[inventory_hostname].ec2_tag_service == 'idsvarnish' %}\
                        {{ varnish_instances.ids.frontend.port }}\
                   {% elif hostvars[inventory_hostname].ec2_tag_service == 'hxvarnish' %}\
                        {{ varnish_instances.hx.frontend.port }}\
                   {% endif %}"
  vars_files:
      - vars/common_vars.yml
      - vars/loris_dedicated_varnish_vars.yml

  tasks:
      - name: install varnish
        include_role:
            name: external/geerlingguy.varnish
        when: is_varnish is defined and is_varnish == 'varnish'

      - name: enable varnishlog
        include_role:
            name: varnishlog
        when: is_varnish is defined and is_varnish == 'varnish'


- hosts: '{{ target_hosts | default("tag_service_reverseproxy", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars_files:
      - vars/common_vars.yml
      - vars/loris_dedicated_varnish_vars.yml

  handlers:
    - include: handlers/main.yml

  tasks:
      - name: setup proxy
        include_role:
            name: nginx
        vars:
            static_dir: '{{ service_static_dir }}'
            nginx_template_path: roles/nginx/templates/nginx_loris.j2


- hosts: '{{ target_hosts | default("all", true) }}'
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars:
      project_name: '{{ hostvars[inventory_hostname].ec2_tag_project | mandatory}}'
      service_role: '{{ hostvars[inventory_hostname].ec2_tag_service | mandatory}}'
      cluster_env: '{{ (hostvars[inventory_hostname].ec2_tag_cluster == "prod")| ternary("prod", "devo") }}'
      cronjob_scripts_dir: '/usr/local/bin'
      cloudwatch_namespace: '{{ cloudwatch_namespace_prefix }}/{{ project_name }}'
      is_varnish: '{{ service_role | regex_search("varnish") }}'
  vars_files:
      - vars/common_vars.yml
      - vars/loris_dedicated_varnish_vars.yml

  tasks:

      - debug:
          msg: "project_name={{ project_name }}; service_role={{ service_role }}; cluster_env={{ cluster_env }}; namespace={{ cloudwatch_namespace }}"

      #
      # 19nov18 naomi: skipping since this is done via cloudformation
      # -------------------------------------------------------------
      # associate proper instance profile for permissions
      #- import_tasks: roles/external/nmaekawa.iam-instance-profile/tasks/associate_iam_instance_profile.yml
      #  vars:
      #      instance_profile_name: "hx_{{ project_name }}-{{ cluster_env }}_instance_profile"
      #      instance_id_to_associate: '{{ hostvars[inventory_hostname].ec2_id }}'
      #  when: "use_aws"

      - import_role:
          name: external/Stouts.users
        vars:
            users_enabled: yes
            users_users:
                - name: cloudwatch
                  authorized: []
            users_to_install:
                - cloudwatch
        when: "use_aws"

      - import_role:
          name: external/nmaekawa.cloudwatch
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: cloudwatch
        when: "use_aws"

      # install script for syslog backup
      - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_backup.yml
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: root
            s3_backup_prefix: '{{ cluster_env }}/{{ project_name }}'
            file_backup_prefix: '{{ service_role }}_{{ ansible_ec2_instance_id }}'
            files_to_backup:
                - /var/log/syslog.1
        when: "use_aws"

      # install script for nginx logs backup
      - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_backup.yml
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: root
            s3_backup_prefix: '{{ cluster_env }}/{{ project_name }}'
            file_backup_prefix: '{{ service_role }}_{{ ansible_ec2_instance_id }}'
            files_to_backup:
                - /var/log/nginx/access.log.1
                - /var/log/nginx/error.log.1
        when: "use_aws and hostvars[inventory_hostname].ec2_tag_service == 'reverseproxy'"

      # install script for varnish logs backup
      - import_tasks: roles/external/nmaekawa.cloudwatch/tasks/install_s3_backup.yml
        vars:
            script_install_dir: '{{ cronjob_scripts_dir }}'
            cronjob_owner: root
            s3_backup_prefix: '{{ cluster_env }}/{{ project_name }}'
            file_backup_prefix: '{{ service_role }}_{{ ansible_ec2_instance_id }}'
            files_to_backup:
                - /var/log/varnish/varnishncsa.log.1
        when: "use_aws and is_varnish is defined and is_varnish == 'varnish'"



      # install script for images sync, if images instance
      - import_tasks: roles/hx.loris/tasks/setup_images_sync.ym
        vars:
            s3_sync_bucket_name: '{{ s3_source_bucket_name }}'
            s3_sync_prefix: 'images'
            target_s3_sync_dir: '{{ service_images_dir }}'
        when: "use_aws and hostvars[inventory_hostname].ec2_tag_service == 'loris'"


      - name: run initial s3 sync for images
        become: yes
        become_user: '{{ service_user }}'
        shell: >
            /usr/bin/aws s3 sync
            "s3://{{ s3_source_bucket_name }}/images"
            "{{ service_images_dir }}"
            2>&1 | logger -t "[s3 sync INITIAL]"
        when: "use_aws and hostvars[inventory_hostname].ec2_tag_service == 'loris'"

      - name: run initial s3 sync for loris cache
        become: yes
        become_user: '{{ service_user }}'
        shell: >
            /usr/bin/aws s3 sync
            "s3://{{ s3_source_bucket_name }}/loris-cache"
            "{{ service_cache_dir }}"
            2>&1 | logger -t "[s3 sync INITIAL]"
        when: "use_aws and hostvars[inventory_hostname].ec2_tag_service == 'loris'"




