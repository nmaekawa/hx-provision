
  #
  # when using rds, we have to move the db dumps to another instance
  #
  # ALWAYS ADD -e project_name=<project_name> to ansible-playbook extra args
  # e.g. -e project_name=catchpy to config backups for catchpy db
  #

- import_playbook: common_play.yml

- hosts: "{{ target_hosts | default('all', true) }}"
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars_files:
    - vars/common_vars.yml
    - vars/postgres_vars.yml

  handlers:
      - include: handlers/main.yml

  tasks:
    - include_role:
        name: external/Stouts.users
      vars:
        users_users: "{{ [db_backup_local_user] }}"

    - include_role:
        name: external/nmaekawa.extra-ebs
      when: use_aws

    - name: install packages jq, aws
      apt:
        name: ['jq', 'awscli']
        state: present

    - name: install pg client
      include_tasks: roles/external/nmaekawa.postgres/tasks/pg_install_client.yml



- hosts: "{{ target_hosts | default('all', true) }}"
  remote_user: "{{ my_remote_user }}"
  become: yes
  become_user: root
  vars_files:
    - vars/common_vars.yml
    - vars/postgres_vars.yml
    - vars/{{ project_name }}_vars.yml

  tasks:
    - ec2_metadata_facts:
      when: ec2_tag_cluster == 'prod'

    - name: create dirs
      file:
        path: "{{ item }}"
        owner: "{{ db_backup_user }}"
        group: "{{ db_backup_group }}"
        mode: 0755
        state: directory
      with_items: ["{{ db_backup_dir }}/{{ service_name }}", "{{ db_bin_dir }}"]

    - name: drop script to perform data backups
      template:
        src: roles/webapp_install/templates/cronjob_db_backup.sh.j2
        dest: "{{ db_bin_dir }}/pg_datadump_{{ service_name }}.sh"
        owner: "{{ db_backup_user }}"
        group: "{{ db_backup_group }}"
        mode: 0754
      when: ec2_tag_cluster == "prod"

    - name: cronjob for data backup
      cron:
        name: "daily postgres data dump for {{ service_name }}"
        user: "{{ db_backup_user }}"
        hour: "6"  # this is UTC, so ~2am EDT or ~1am EST
        minute: "0"
        state: present
        job: >
          {{ db_bin_dir }}/pg_datadump_{{ service_name }}.sh --db "{{ service_db_name }}"
          --outdir "{{ db_backup_dir }}/{{ service_name }}"
          --days {{ service_db_backup_local_retention_in_days }} 2>&1 | logger -t "[db backup]"
      when: ec2_tag_cluster == "prod"

    - name: install s3 cronjob for db dumps
      cron:
        name: "s3 sync for db dumps"
        user: "{{ db_backup_user }}"
        hour: "6"     # this is UTC, so ~2am EDT or ~1am EST
        minute: "30"  # check when dumps are performed to schedule after that
        state: present
        job: >
          /usr/bin/aws s3 sync
          {{ db_backup_dir }}/{{ service_name }}
          s3://{{ s3_backup_bucket_name }}/{{ ec2_tag_cluster }}/{{ project_name }}/pgdump_taken_from_{{ ansible_ec2_instance_id }}
      when: ec2_tag_cluster == "prod"

